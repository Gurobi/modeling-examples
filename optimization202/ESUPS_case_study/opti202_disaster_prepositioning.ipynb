{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disaster Pre-positioning with Mathematical Optimization\n",
    "\n",
    "In this notebook, we will take you through the end-to-end process of how ESUPS transformed from a simple idea into a global initiative that is reshaping disaster response logistics. We will delve into the crucial role that optimization plays in this transformation, demonstrating how ESUPS utilizes advanced algorithms to optimize the allocation and movement of disaster relief supplies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/ESUPS-Logo.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step in the journey is reading and cleaning the data. We won't focus too much on this step because the really interesting stuff happens once we have the data loaded. However, we will showcase how the data needs to be formatted for Gurobi. If this is your first pass of the case study, feel free to skip over this section and return to it later when you want a more in-depth overview of formatting the data.\n",
    "\n",
    "Before we begin, I wanted to make a quick note about a line of code you'll see repeated throughout the notebook: %%script false --no-raise-error\n",
    "\n",
    "\n",
    "- **NOTE:** This is just cell magic (if you're unfamiliar, think of it as using the cmd line) telling the notebook not to run this cell. We'll use it in various places to demonstrate ideas or code snippets that are not meant to produce an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 main libraries we'll be using to solve this problem. The other import statements can be explicitly seen in setup_imports.py, but is primarily for getting all relevant methods from the source repo into our namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt              \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "#now hidden code\n",
    "from setup_imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next and final step in this section is to define what data we'll be using to implement the solver, and in this case, we'll be using real-world data from Madagascar. Madagascar is the fourth largest island in the world and is located off the southeastern coast of Africa. Known for its unique biodiversity, approximately 90% of its wildlife is found nowhere else on Earth. The island's diverse ecosystems range from rainforests to deserts, making it a hotspot for biological research and conservation efforts.\n",
    "\n",
    "However, Madagascar is also prone to natural disasters, including cyclones, floods, and droughts, all of which have a significant impact on its population and infrastructure. These disasters pose challenges for disaster response and resource allocation, making it an ideal case study for optimization and data-driven decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Up Our Data\n",
    "COUNTRY = \"madagascar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reading and Cleaning \n",
    "Now we'll load the data into RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "reader = CsvProblemReader()\n",
    "dataset = reader.read(DATA_DIR / COUNTRY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we won't be focusing on reading in the data, it's always useful to see the general structure. Feel free to skip this part on your first high-level pass and come back to it later when you better understand the details.\n",
    "\n",
    "You can see in the code below all the factors that go into our model. While intimidating at first glance, this dataset class is a way to tie several related lists and dictionaries to the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "#The class is as follows\n",
    "@dataclass(frozen=True)\n",
    "class Dataset:\n",
    "    depots: list[Depot]\n",
    "    disasters: list[Disaster]\n",
    "    disaster_locations: list[DisasterLocation]\n",
    "    probabilities: dict[Disaster, float]\n",
    "    items: list[Item]\n",
    "    transport_modes: list[TransportMode]\n",
    "    inventory: dict[Tuple[Depot, Item], int]\n",
    "    inventory_scenarios: dict[str, dict[Tuple[Depot, Item], int]]\n",
    "    distance: DistanceMatrix\n",
    "    people_affected: dict[Tuple[DisasterImpact, Item], float]\n",
    "    persons_per_item_general: dict[Tuple[DisasterImpact, Item], float]\n",
    "    persons_per_item_monthly: dict[Tuple[DisasterImpact, Item], float]\n",
    "    disaster_affected_totals: dict[str, int]\n",
    "\n",
    "    _zero_demand_threshold = 1e6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the dataset fields are mainly data structures holding other objects. Now we won't go into all these here, but it can be useful to see how they are set up. Let's take a look at one such object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Item:\n",
    "    id: str = field(hash=True)\n",
    "    weight: float = field(repr=False)  # Metric tons\n",
    "    volume: float = field(repr=False)  # Cubic metres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's a simple data structure, and most of the code here is actually more about organization and readability, which is incredibly useful in production code. Credits here go to Ben Kennerley, who has been working with ESUPS to enhance STOCKHOLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always useful to see the general structure of data and the broader context of the problem. Now that we've cleaned and loaded it, let's take some time to understand it. The goal here should be to get comfortable with the problem as a whole and give you an intuitive understanding of what we are solving. So, the emphasis isn't on the code. For this reason, most of the following cells have been written as functions to collapse more easily across different platforms. Your goal shouldn't be to understand the libraries used to map, but instead on how Madagascar looks at a high level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Where is Everything?\n",
    "One of the first things we'll look at is where the supplies are relative to disasters right now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_locations():\n",
    "    warehouses = [['warehouses',\n",
    "                   depot.latitude,\n",
    "                   depot.longitude] \n",
    "                   for depot in dataset.depots]\n",
    "\n",
    "    disasters = [['disasters',\n",
    "                  disaster_locations.latitude,\n",
    "                  disaster_locations.longitude] \n",
    "                  for disaster_locations in dataset.disaster_locations]\n",
    "\n",
    "    dfw = pd.DataFrame(warehouses)\n",
    "    dfw.columns = ['Type', 'Lat', 'Long']\n",
    "\n",
    "    dfd = pd.DataFrame(disasters)\n",
    "    dfd.columns = ['Type', 'Lat', 'Long']\n",
    "\n",
    "    df_combined = pd.concat([dfw[['Lat', 'Long', 'Type']], dfd[['Lat', 'Long', 'Type']]], ignore_index=True)\n",
    "\n",
    "    fig = px.scatter_mapbox(df_combined, \n",
    "                            lat=\"Lat\", \n",
    "                            lon=\"Long\", \n",
    "                            color=\"Type\",\n",
    "                            color_discrete_sequence=px.colors.qualitative.Safe,\n",
    "                            zoom=4.5)\n",
    "    \n",
    "    # Use a minimalist map style to reduce clutter\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "\n",
    "    # Optionally center the map around the mean latitude and longitude of your points\n",
    "    mean_lat = df_combined['Lat'].mean()\n",
    "    mean_long = df_combined['Long'].mean()\n",
    "    fig.update_layout(mapbox_center={\"lat\": mean_lat, \"lon\": mean_long})\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "graph_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the warehouses are aligned closely with the most prominent disaster sites*, so assuming they are built to a level that can survive and protect against those disasters, Madagascar should be in a strong position in terms of coverage. However, there's more than meets the eye. Let's dive a little deeper!\n",
    "\n",
    "Hopefully, now that you've gotten a sense of the country and the layout, we'll turn off some of the more detailed parts (such as roads and urbanization) so it's simpler to see what’s going on.\n",
    "\n",
    "- **NOTE:** locations of warehouses have been modified for this case study for safety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 What Supplies are Available?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important question to ask at this point is: what do we have inside the warehouses? It's great that there seems to be good coverage that ensures a warehouse is nearby for any disaster, but if one of them is full of kitchen sets and there's a flood, they might not be as immediately useful as buckets or tarpaulins. So, let's look at the overall breakdown of supplies by warehouse/location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample Data\n",
    "def make_barchart():\n",
    "    items = {}\n",
    "    for x in dataset.inventory:\n",
    "        if x[1].id in items:\n",
    "            items[x[1].id] += dataset.inventory[x]\n",
    "        else:\n",
    "            items[x[1].id] = dataset.inventory[x]\n",
    "\n",
    "    items = dict(sorted(items.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Extract keys and values from the dictionary\n",
    "    categories = list(items.keys())\n",
    "    values = list(items.values())\n",
    "\n",
    "    # Normalize the values for color scale\n",
    "    normalized_values = np.array(values) / max(values)\n",
    "\n",
    "    # Define a color scale (e.g., 'Viridis', 'Cividis', 'Plasma', etc.)\n",
    "    colorscale = 'Cividis'\n",
    "\n",
    "    def format_number(num):\n",
    "        if num >= 1_000_000:\n",
    "            return f'{num/1_000_000:.1f}M'  # Format as millions\n",
    "        elif num >= 1_000:\n",
    "            return f'{num/1_000:.0f}k'  # Format as thousands\n",
    "        else:\n",
    "            return str(num)  # Show the number as is if below 1,000\n",
    "\n",
    "    # Create formatted text for display\n",
    "    formatted_text = [format_number(v) for v in values]  # Use the custom formatting function\n",
    "\n",
    "    # Create a bar chart with a color continuum\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Bar(\n",
    "                x=categories,\n",
    "                y=values,\n",
    "                marker=dict(\n",
    "                    color=normalized_values,  # Use normalized values for the color scale\n",
    "                    colorscale=colorscale,  # Apply the chosen color scale\n",
    "                    showscale=False  # Hide the color scale bar\n",
    "                    \n",
    "                ),\n",
    "                texttemplate='%{text}',  # Explicitly set text template\n",
    "                text=formatted_text,  # Display formatted text with 'k' and 'M' suffixes\n",
    "                hovertemplate='<b>%{x}</b><br>Quantity: %{y}<extra></extra>',  # Show exact hover info\n",
    "                textposition='auto',  # Automatically position the text\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': \"Distribution of Supplies for Disaster Relief\",\n",
    "            'y': 0.95,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'\n",
    "        },\n",
    "        xaxis_title=\"Supplies\",\n",
    "        yaxis_title=\"Quantity\",\n",
    "        yaxis_type=\"log\",  # Logarithmic scale for better visualization\n",
    "        xaxis=dict(tickangle=-45),  # Rotate x-axis labels for better readability\n",
    "        plot_bgcolor='white',  # Set background color to white for better contrast\n",
    "        xaxis_tickfont_size=10,  # Font size for x-axis labels\n",
    "        yaxis_tickfont_size=10,  # Font size for y-axis labels\n",
    "        margin=dict(l=40, r=40, t=80, b=100),  # Adjust margins\n",
    "    )\n",
    "\n",
    "    # Add annotations to highlight key insights\n",
    "    fig.add_annotation(\n",
    "        x=categories[0],  # Example: Highlighting the highest value category\n",
    "        y=values[0],\n",
    "        text=\"Highest Quantity\",\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        ax=-40,\n",
    "        ay=-40\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "make_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the supplies skew heavily towards buckets, water containers, and mosquito nets, which makes sense for an island nation. But while it's great that we have a lot of buckets, it won't do us too much good if none of them are at the coast, for instance.\n",
    "\n",
    "- **NOTE:** From here on out in the case study, we're going to focus on just buckets as they're the most prevalent item and, for the purposes of this case, it's time consuming and repetitive to analyze all 15 item types of supplies available. \n",
    "\n",
    "As you'll see later in the notebook, it's a simple matter to apply the analysis of any one of the supply items to all 15 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 Where are the Supplies?\n",
    "\n",
    "Let's take a look at the following map to get a better picture of where everything is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_supplies():\n",
    "  supplies=[[x[0].latitude,\n",
    "             x[0].longitude,\n",
    "             dataset.inventory[x]]\n",
    "             for x in dataset.inventory if x[1].id=='Buckets']\n",
    " \n",
    "  df=pd.DataFrame(supplies)\n",
    "  df.columns = ['Lat', 'Long', 'Buckets']\n",
    "\n",
    "  fig = px.scatter_mapbox(df, \n",
    "                        lat=\"Lat\", \n",
    "                        lon=\"Long\", \n",
    "                        size=\"Buckets\",\n",
    "                        #size_max=10,  # Maximum size of the marker\n",
    "                        #size_min=5,\n",
    "                        color_discrete_sequence=px.colors.qualitative.Safe,\n",
    "                        zoom=4.5,  # Adjust zoom level as needed\n",
    "                        )\n",
    "\n",
    "  # Optionally center the map around the mean latitude and longitude of your points\n",
    "  # Use a minimalist map style to reduce clutter\n",
    "  fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "\n",
    "  mean_lat = df['Lat'].mean()\n",
    "  mean_long = df['Long'].mean()\n",
    "  fig.update_layout(mapbox_center={\"lat\": mean_lat, \"lon\": mean_long})\n",
    "  fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "  fig.show()\n",
    "graph_supplies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the supplies are largely located on the eastern coastline of the country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.5 Not All Disasters Are Built the Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_impacts():\n",
    "    \n",
    "    # Example values for l and h\n",
    "    l = -0.1\n",
    "    h = 0.1\n",
    "\n",
    "    # Sample data preparation\n",
    "    disasters = [[disasters.type.id,\n",
    "                disaster_locations.latitude,\n",
    "                disaster_locations.longitude,\n",
    "                dataset.disaster_affected_totals[key]] \n",
    "                for disasters, disaster_locations, key in zip(dataset.disasters, dataset.disaster_locations, dataset.disaster_affected_totals)]\n",
    "\n",
    "    df = pd.DataFrame(disasters)\n",
    "    df.columns = ['Type', 'Lat', 'Long', 'People Impacted']\n",
    "\n",
    "    fig = px.scatter_mapbox(df, \n",
    "                            lat=\"Lat\", \n",
    "                            lon=\"Long\", \n",
    "                            color=\"Type\", \n",
    "                            size=\"People Impacted\",\n",
    "                            #size_max=10,  # Maximum size of the marker\n",
    "                            #size_min=5,\n",
    "                            zoom=4.5,  # Adjust zoom level as needed\n",
    "                            color_discrete_sequence=px.colors.qualitative.Safe,\n",
    "                            )\n",
    "\n",
    "    # Optionally center the map around the mean latitude and longitude of your points\n",
    "    # Use a minimalist map style to reduce clutter\n",
    "    fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "\n",
    "    mean_lat = df['Lat'].mean()\n",
    "    mean_long = df['Long'].mean()\n",
    "    fig.update_layout(mapbox_center={\"lat\": mean_lat, \"lon\": mean_long})\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "graph_impacts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.6 How Do Disasters and Supplies Compare in Scale?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see small blue circles within the red circles, representing supply quantities. The size of each red circle indicates the estimated number of people needing supplies in a disaster-affected area. Meanwhile, the blue circles show the total number of items available, adjusted by how many people each item can serve. For example, one large bucket is estimated to meet the needs of 2.5 people, so the blue circles display the quantity of supplies as $2.5 \\cdot Supplies$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_overlap():\n",
    "  supplies=[['supplies',\n",
    "             x[0].latitude,\n",
    "             x[0].longitude,\n",
    "             dataset.inventory[x]*2.5] #this is people per bucket\n",
    "             for x in dataset.inventory if x[1].id=='Buckets']\n",
    " \n",
    "  supplies=pd.DataFrame(supplies)\n",
    "  supplies.columns = ['Type','Lat', 'Long', 'Scale']\n",
    "\n",
    "\n",
    "  # Sample data preparation\n",
    "  disasters = [['disasters',\n",
    "                disaster_locations.latitude,\n",
    "                disaster_locations.longitude,\n",
    "                dataset.disaster_affected_totals[key]] \n",
    "                for disasters, disaster_locations, key in zip(dataset.disasters, dataset.disaster_locations, dataset.disaster_affected_totals)]\n",
    "\n",
    "  disasters = pd.DataFrame(disasters)\n",
    "  \n",
    "  \n",
    "  disasters.columns = ['Type', 'Lat', 'Long', 'Scale']\n",
    "\n",
    "  df_combined = pd.concat([supplies[['Type','Lat', 'Long', 'Scale']],\n",
    "                           disasters[['Type','Lat', 'Long', 'Scale']]],\n",
    "                           ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  fig = px.scatter_mapbox(df_combined, \n",
    "                        lat=\"Lat\", \n",
    "                        lon=\"Long\", \n",
    "                        size=\"Scale\",\n",
    "                        color='Type',\n",
    "                        size_max=40,  # Maximum size of the marker\n",
    "                        #size_min=5,\n",
    "                        zoom=4.5,  # Adjust zoom level as needed\n",
    "                        color_discrete_sequence=px.colors.qualitative.Safe,\n",
    "                        )\n",
    "\n",
    "  # Optionally center the map around the mean latitude and longitude of your points\n",
    "  # Use a minimalist map style to reduce clutter\n",
    "  fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "\n",
    "  mean_lat = df_combined['Lat'].mean()\n",
    "  mean_long = df_combined['Long'].mean()\n",
    "  fig.update_layout(mapbox_center={\"lat\": mean_lat, \"lon\": mean_long})\n",
    "  fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "\n",
    "  fig.show()\n",
    "\n",
    "graph_overlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 How Does ESUPS Communicate this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESUPS' platform  [Stockholm](https://www.esups-stockholm.org/#/private/signin), which is hosting this model (you can apply for access by visiting the homepage linked above), has two main pages, the first is the context page, and explains the context of the problem that we've been discussing in the past few sections, along with additional details about their mission and collaborating organizations. We'll look at this one first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Real-time Data Visualization** : Progressive Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to take a slight detour here to look at how all this information is communicated in real life! You can skip this section without concern for missing important information. \n",
    "\n",
    "As we've seen, getting an intuitive understanding of disasters and humanitarian supplies can be tricky when working with a new country. In fact, it's one of the main challenges ESUPS has faced in driving adoption and explaining why their work is so important. \n",
    "\n",
    "Data Visualization isn't an easy task, but let's take a look at how ESUPS started and how they're continuing to improve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='images/Old_Stockholm.png', width=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one of the earlier versions of the ESUPS dashboard; even in v1, it played a critical role in enabling the organization to quickly deliver a functional product that demonstrated tangible results to other non-profits. This initial version provided the essential tools needed to map stockpiles and showcase the value of the platform in real-world scenarios. By prioritizing functionality and speed, ESUPS was able to meet the immediate needs of its partners, proving the concept and gaining crucial buy-in from stakeholders.\n",
    "\n",
    "The lesson here: Start with the tools and skills available and always look for ways to improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='images/Disaster_Dashboard.png',width=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimizing!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Intro to the ESUPS Optimization Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let:\n",
    "\n",
    "- $\\tau_{ij}$ be the time to ship a single item from warehouse $i$ to the disaster\n",
    "\n",
    "- $y_i$ be the amount of supplies to send from warehouse $i$ to our disaster\n",
    "\n",
    "- $x_i$ be the starting inventory at each warehouse\n",
    "\n",
    "- $d$ be the demand for an item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have described what we can change with our variables, we can figure out how to represent the objective function!\n",
    "$$\n",
    "\\min_y \\sum_i \\tau_{i}\\cdot y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constraints are:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{s.t.}  & \\sum_{i} & y_{i}&=d & & \\hspace{.2cm} \\text{(total supplies sent must meet demand)}\\\\\n",
    "\n",
    "& & y_i       &\\leq x_i & \\forall i \\in I& \\hspace{.2cm}\\text{(you can't send more than a warehouse has)}\\\\\n",
    "\n",
    " &\\text{} & y_{i} &\\geq 0 &\\forall i \\in I& \\hspace{.2cm} \\text{(you can't send negative supplies)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <strong>Note!</strong>\n",
    "    <p>Decision variables in mathematical optimization problems are typically assumed to be nonnegative. So while you'll see these constraints in formulations (i.e. the algebraic representations), you may not see the code for it since it's likely assumed to be nonnegative.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's solve this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create The Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep distance matrix\n",
    "df_distance, relevant_warehouses, BucketsNeeded = get_distance_matrix(dataset)\n",
    "t = df_distance.drivingTime_hrs\n",
    "n = len(relevant_warehouses)\n",
    "\n",
    "# Create model\n",
    "model = gp.Model(\"simple_Allocation\") \n",
    "\n",
    "# Add decision variables\n",
    "y=model.addVars(n, vtype=GRB.INTEGER, name=\"Warehouse_Allocation\")\n",
    "\n",
    "#Add constraint to meet demand\n",
    "model.addConstr(gp.quicksum(y[i] for i in range(n))==BucketsNeeded,name='Meet_Demand')\n",
    "\n",
    "# Add in warehouse_constraints\n",
    "for i, supplies in enumerate(relevant_warehouses):\n",
    "    model.addConstr(y[i] <= supplies[2], name=f\"warehouse_endowment_{i}\")\n",
    "\n",
    "# Note we don't have a constraint for y >= 0 since it's assumed in the variable definition\n",
    "# Add objective\n",
    "objective = gp.quicksum(t[i] * y[i] for i in range(n))\n",
    "model.setObjective(objective, GRB.MINIMIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire up the solver!\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's analyze the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show Solution\n",
    "b=[]\n",
    "for v, total, dis in zip(model.getVars(),relevant_warehouses,list(df_distance['drivingTime_hrs'])):\n",
    "    if v.VarName[0:20]== 'Warehouse_Allocation':\n",
    "        #print('%s %g | total= %g | distance=%g' % (v.VarName, v.X,total[2],dis))\n",
    "        b.append([v.VarName, v.X,total[2],dis])\n",
    "b=pd.DataFrame(b)\n",
    "b.columns=['Var','amount','possible','distance']\n",
    "b.sort_values('distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you may have noticed that this feels like overkill. If we want to position supplies to respond to a known disaster, you might think that we should just put them as close as possible. It's an intuitive solution that can be solved with a simple greedy algorithm. But of course, life is never that simple. \n",
    "\n",
    "Now that we've got the initial problem outlined, let's start making it more realistic with two additions:\n",
    "1.\tInstead of preparing for only one disaster, let's prepare for all the disasters that might occur.\n",
    "2.\tInstead of being an omniscient observer, let's say we aren't sure where the next disaster will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Including All Disasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's explicitly define our new problem with the additional requirements outlined in the previous section so we're all on the same page. Our first step is to add in the fact that there are more disasters than just one. We can do that by including a variable to denote which disaster we're talking about.\n",
    "\n",
    "Let:\n",
    "\n",
    "- $k$ be the disaster scenario at hand i.e. a storm, earthquake, or epidemic\n",
    "- $j$ be the location of the disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scenario $k$ with the disaster located at $j$, the time for a warehouse $i$  to send $y_i$ items is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\tau_{ij}\\cdot y^k_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating for all warehouses gives us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \\sum_i \\tau_{ij}\\cdot y^k_i $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating for all disasters gives us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum_k \\sum_i \\tau_{ij}\\cdot y^k_i $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formulation doesn't change any of the solutions we found in the last section, instead, it's leveraging the power of our notation to be able to solve for the optimal allocation for every disaster in one fell swoop! It's been a while since we looked at the original problem in its entirety, so let's take a step back to understand why this is so important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to solving, let's add in one more small factor. Different disasters occur at different rates. A landlocked nation may be less likely to experience a disaster caused by a tropical storm than an earthquake, so shouldn't we weigh the response time to earthquakes more than that of a storm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Accounting for Randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most difficult tasks that we can encounter in data science problems is randomness or as it's often called \"stochastic\" elements. This can be seen in all kinds of ways, but in our case study, we're going to look at how we account for not knowing which disaster will hit next or even several years in the future. The way we do this is to create a stochastic model, which may initially seem intimidating, but in discrete events like this, it's super easy.\n",
    "\n",
    "If you're familiar with expected value this will quickly make sense, but no need to have any prior experience! The idea is that we weigh the outcome of the event (i.e. total travel time in this case) by the probability it occurs. So, if an earthquake is 3 times as likely as a flood, we would rewrite the equation as:\n",
    "\n",
    "$$.75 \\cdot\\text{(travel time earthquake)} + .25 \\cdot\\text{(travel time flood)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 More On Expected Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't seen expected value before or if it's just been a while and you'd like a refresher, try some of the practice problems below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we solve expected value for discrete outcomes, we take the value/outcome/payoff of each possible event and discount it by the probability that it actually occurs. So it follows the form:\n",
    "\n",
    "$$\n",
    "E[X]=p_1(x_1)+p_2(x_2)+ ... + p_n(x_n)\n",
    "$$\n",
    "To simplify this notation we typically write this as a series:\n",
    "\n",
    "$$\n",
    "E[X]=\\sum_{i=1}^{i=n} p_i \\cdot x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starter Problems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Coin Flip: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we play a coin flipping game. Every time we flip the coin and it lands on heads, you get a dollar, and every time it lands on tails, you have to pay a dollar. How much are you expected to make or lose when playing this game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_3_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Coin Flip Variant: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's change the game a little, say you now get 5 paid dollars when the coin lands on heads and only have to pay 3 dollars when it lands on tails. Would you play? How much are you expected to make or lose when playing this game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_3_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Dice Game:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suppose you roll a fair six-sided die. If it lands on 6, you win $10; otherwise, you lose $2. What is the expected value of this game? Should you play it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[X] &= \\left(\\frac{1}{6} \\times 10\\right) + \\left(\\frac{5}{6} \\times (-2)\\right)\n",
    "\\\\\n",
    "E[X] &= \\left(\\frac{10}{6}\\right) + \\left(\\frac{-10}{6}\\right)\n",
    "\\\\\n",
    "E[X] &= \\frac{10 - 10}{6} = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "**Answer**: The expected value is $\\$0$. This means, on average, you neither gain nor lose money from playing this game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two-Coin Game:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You flip two fair coins. If both coins land on heads, you win $8. If one coin lands on heads and the other on tails, you win $4. If both coins land on tails, you lose $5. What is the expected value of playing this game?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution:\n",
    "\n",
    "\n",
    "- Probability of two heads (HH): $\\frac{1}{4}$\n",
    "- Probability of one head and one tail (HT or TH): $\\frac{1}{2}$\n",
    "- Probability of two tails (TT): $\\frac{1}{4}$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[X] &= \\left(\\frac{1}{4} \\times 8\\right) + \\left(\\frac{1}{2} \\times 4\\right) + \\left(\\frac{1}{4} \\times (-5)\\right)\n",
    "\\\\\n",
    "E[X] &= \\left(2\\right) + \\left(2\\right) + \\left(-1.25\\right)\n",
    "\\\\\n",
    "E[X] &= 2 + 2 - 1.25 = 2.75\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "**Answer**: The expected value is $\\$2.75$. This means, on average, you gain $\\$2.75$ per game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermediate Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Card Drawing Game:**\n",
    "You draw a card from a standard deck of 52 playing cards. If you draw an Ace, you win $15. If you draw a King, Queen, or Jack, you win $5. For any other card, you lose $3. What is the expected value of this game?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution:\n",
    "\n",
    "- Probability of drawing an Ace: $\\frac{4}{52} = \\frac{1}{13}$\n",
    "- Probability of drawing a King, Queen, or Jack: $\\frac{12}{52} = \\frac{3}{13}$\n",
    "- Probability of drawing any other card: $\\frac{36}{52} = \\frac{9}{13}$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\n",
    "E[X] &= \\left(\\frac{1}{13} \\times 15\\right) + \\left(\\frac{3}{13} \\times 5\\right) + \\left(\\frac{9}{13} \\times (-3)\\right)\n",
    "\\\\\n",
    "\n",
    "\n",
    "E[X] &= \\left(\\frac{15}{13}\\right) + \\left(\\frac{15}{13}\\right) + \\left(\\frac{-27}{13}\\right)\n",
    "\\\\\n",
    "\n",
    "\n",
    "E[X] &= \\frac{15 + 15 - 27}{13} = \\frac{3}{13}\n",
    "\n",
    "\\\\\n",
    "E[X] &\\approx 0.23\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Answer**: The expected value is approximately \\$0.23. On average, you gain 23 cents per draw.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $P^k$ be the probability of disaster $k$ and $t^k$ be the total travel time involved in disaster $k$ in the previous sections. Using our definition of expected value, this gives us:\n",
    "\n",
    "$$ \\sum_k P^k \\cdot t^k$$\n",
    "\n",
    "Now you might notice that we have already written an equation for the total travel time for disaster $k$ ! Substituting this in we get:\n",
    "\n",
    "$$\\sum_k P^k \\sum_i \\tau_{ij}\\cdot y^k_i$$\n",
    "\n",
    "So, our final task right now is to minimize the time required to get supplies to a disaster given how likely each disaster is to occur:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\min_y \\sum_k P^k \\sum_i \\tau_{ij}\\cdot y^k_i\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the constraints are almost unchanged. The only added part is that all probabilities must sum to one, which is always the case:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\n",
    "\n",
    "\\text{s.t.}  & \\sum_{i} & y^k_{i}&=d^k & & \\hspace{.2cm} \\text{(total supplies sent must meet demand)}\\\\\n",
    "\n",
    "& & y^k_i       &\\leq x_i & \\forall i \\in I& \\hspace{.2cm}\\text{(you can't send more than a warehouse has)}\\\\\n",
    "\n",
    " &\\text{} & y^k_{i} &\\geq 0 &\\forall i \\in I& \\hspace{.2cm} \\text{(you can't send negative supplies)}\\\\\n",
    "\n",
    "\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we calculate the probability though? Well, we have good long-term data on what disasters have affected which countries. For now, we can go through that data and calculate the probability of disaster k by counting how many times it has occurred and dividing by the number of total disasters:\n",
    "\n",
    "$$ P^k = \\frac{k}{\\|K\\|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have the equation, we can let the model go ahead and let Gurobi solve it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand, probs = get_probs(dataset)\n",
    "\n",
    "n = len(relevant_warehouses)\n",
    "m = len(demand)\n",
    "a = []\n",
    "\n",
    "# Create an array of driving times based on the df_distance DataFrame\n",
    "t = [int(row['drivingTime_hrs']) for i, row in df_distance.iterrows()]\n",
    "c=pd.DataFrame(t)\n",
    "\n",
    "# Amount to take per Warehouse\n",
    "y = model.addVars(m, n, vtype=GRB.INTEGER, name=\"Warehouse_Allocation\")\n",
    "\n",
    "# Add constraints to meet demand for each disaster scenario (k)\n",
    "for k in range(m):\n",
    "    # Demand constraints\n",
    "    model.addConstr(gp.quicksum(y[k, i] for i in range(n)) == demand[k], name=f\"Meet_Demand_K:{k}\")\n",
    "    \n",
    "    # Warehouse constraints\n",
    "    for i, supplies in enumerate(relevant_warehouses):\n",
    "        model.addConstr(y[k, i] <= supplies[2], name=f\"warehouse_endowment_K:{k}_I:{i}\")\n",
    "\n",
    "# Objective function to minimize the weighted driving time using T as a parameter\n",
    "objective = gp.quicksum(\n",
    "    probs[k] * gp.quicksum(t[i] * y[k, i] for i in range(n))\n",
    "    for k in range(m)\n",
    ")\n",
    "\n",
    "# Optimize model\n",
    "model.setObjective(objective, GRB.MINIMIZE)\n",
    "model.optimize()\n",
    "\n",
    "# Store results in the list 'a'\n",
    "for v in model.getVars():\n",
    "    a.append([v.VarName, v.X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(a).iloc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Data Science Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen how the equation uses the uniform distribution to solve the problem, but what if we knew something it didn't? What if knowing that climate change is increasingly energizing large storms, we decide the past hurricane impacts aren't representative of what's to come? In this section we want to prompt you to come up with predictive elements to improve our models. Feel free to use some of the ideas below or go in an entirely new direction!\n",
    "\n",
    "In this section, we encourage you to think creatively about enhancing predictive models for climate-related disasters. Consider how to incorporate novel data sources, feature engineering techniques, and model architectures to improve predictions. Below are some suggested approaches, but feel free to explore entirely new directions!\n",
    "\n",
    "Case Study Focus: Coastal Eastern African Nations\n",
    "\n",
    "Using the disaster impact data for coastal Eastern African nations, can you develop a model to predict how these impacts might escalate for Madagascar in the coming years? Consider not only the historical data but also factors such as changes in sea surface temperatures, shifting storm tracks, population growth along vulnerable coastlines, and evolving infrastructure resilience. Further, can you integrate this predictive model into an optimization framework to better allocate resources for disaster preparedness and response?\n",
    "\n",
    "Potential Approaches to Explore:\n",
    "1. **Comparing Time Series Models:** Traditional statistical time series models like ARIMAX (AutoRegressive Integrated Moving Average with Explanatory Variables) are commonly used to predict future values based on past data. How do these models compare with more advanced Recurrent Neural Network (RNN)-based approaches like Long Short-Term Memory (LSTM) networks or Gated Recurrent Units (GRUs) in capturing long-term dependencies, especially under non-stationary conditions induced by climate change?\n",
    "\n",
    "2.\t**Incorporating Geospatial Data:** Geospatial features, such as latitude, longitude, elevation, and proximity to bodies of water, can play a crucial role in predicting the impact of tropical storms. Can we encode geospatial information using techniques like convolutional neural networks (CNNs) for spatial feature extraction, or leverage more specialized models such as Geographical Weighted Regression (GWR) or Graph Neural Networks (GNNs) to account for spatial dependencies?\n",
    "\n",
    "3.\t**Incorporating Climate Change Projections:** Beyond just historical data, consider how future climate projections can be integrated into the model. Can we use downscaled climate model outputs or ensemble approaches to account for different climate scenarios? How would these scenarios affect the frequency and intensity of tropical storms affecting coastal Eastern African nations?\n",
    "\n",
    "4.\t**Feature Engineering with Climate Indicators:** Introduce climate change indicators as predictive features. For example, how do trends in sea surface temperatures (SSTs), El Niño-Southern Oscillation (ENSO) phases, or the Atlantic Multi-decadal Oscillation (AMO) correlate with storm intensification? Would incorporating these indicators as additional time series variables enhance predictive accuracy?\n",
    "\t\n",
    "5.\t**Hybrid and Ensemble Models:** Can we leverage hybrid models that combine both statistical and deep learning approaches, or use ensemble methods that aggregate predictions from multiple models? For example, combining ARIMAX for short-term predictions with LSTM for capturing long-term trends may provide a more comprehensive forecasting tool.\n",
    "\n",
    "6.\t**Optimization Integration:** Once a reliable predictive model is established, how can it be integrated into an optimization framework for resource allocation? For example, can we build an optimization model that minimizes both the cost of disaster preparedness and the potential loss from future storm impacts?\n",
    "\n",
    "7.\t**Model Explainability and Decision-Making:** How can we ensure that the model is interpretable for decision-makers? Consider the use of techniques like SHAP (SHapley Additive exPlanations) values or LIME (Local Interpretable Model-agnostic Explanations) to explain which factors contribute most to the model’s predictions, helping policymakers make informed decisions.\n",
    "\n",
    "By combining predictive analytics with optimization, we can not only forecast future disaster impacts but also develop actionable strategies for minimizing those impacts. The goal is to make our models both more accurate and more useful in real-world applications, driving better outcomes for communities at risk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Putting it All Together: Optimizing Allocation and Transportation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we can solve for the time it takes to address every single disaster, we can finally answer the original question posed: how do we best allocate supplies to all the warehouses? The key here is to create a second optimization problem. Remember how in our constraints we included that you can't send more than the warehouse has? \n",
    "\n",
    "$$\n",
    "y^k_i       \\leq x_i,\\space  \\forall i \\in I \\hspace{.2cm}\\text{(you can't send more than a warehouse has)}\\\\\n",
    "$$\n",
    "\n",
    "So far, we've just been using the actual allocation we have at each warehouse for $x_i$. But what if those change? Suddenly we would have an entirely new solution. So, if we say that the output of Gurobi (i.e. the allocations $y^k_i \\in Y$) is some function based on our starting amount of warehouses ($X$ where $x_i\\in X$), then we can say:\n",
    "\n",
    "$$Y=f(X)$$ \n",
    "\n",
    "And when we frame it this way, it becomes much more simple to solve! All we need to do is minimize the travel times $Y$. In other words, our problem becomes: \n",
    "\n",
    "\n",
    "$$ \\min_{X} f(X) $$\n",
    "$$\\begin{aligned}\n",
    "\\text{s.t.}  & \\sum_{i} & x_i&=\\chi & & \\hspace{.2cm} \\text{(we allocate all supplies and no more)}\\\\\n",
    "\n",
    " && x_{i} &\\geq 0 &\\forall i \\in I& \\hspace{.2cm} \\text{(you can't allocate negative supplies)}\\\\\n",
    "\n",
    "\\end{aligned}$$\n",
    "\n",
    "Where $\\chi$ is the total amount of supplies we have in the country\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this may initially look intimidating, it is one of the easiest changes to make to our current code. All we are doing is making a decision variable instead of a constant and then constraining it. Let’s substitute back in our equation from the last section the new constraints to see this firsthand. To denote a new decision variable (i.e. a variable that can be changed), all we need to do is add it under the minimization sign. This means minimizing with respect to $x$ and $y$:\n",
    "\n",
    "$$\n",
    "\\min_{x,y} \\sum_k P^k \\sum_i \\tau_{ij}\\cdot y^k_i\n",
    "$$\n",
    "\n",
    "Then all we need to do is update the constraints. I've included the line to make it easier to see what's new as our list grows. It has no mathematical significance. \n",
    "\n",
    "So how do we implement this in Gurobi?\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\n",
    "\n",
    "\\text{s.t.}  & \\sum_{i} & y^k_{i}&=d^k & & \\hspace{.2cm} \\text{(total supplies sent must meet demand)}\\\\\n",
    "\n",
    "& & y^k_i       &\\leq x_i & \\forall i \\in I& \\hspace{.2cm}\\text{(you can't send more than a warehouse has)}\\\\\n",
    "\n",
    " &\\text{} & y^k_{i} &\\geq 0 &\\forall i \\in I& \\hspace{.2cm} \\text{(you can't send negative supplies)}\\\\\n",
    "\\hline \\\\\n",
    "  & \\sum_{i} & x_i&=\\chi & & \\hspace{.2cm} \\text{(we allocate all supplies and no more)}\\\\\n",
    "\n",
    " && x_{i} &\\geq 0 &\\forall i \\in I& \\hspace{.2cm} \\text{(you can't allocate negative supplies)}\\\\\n",
    "\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we Implment this in Gurobi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gp.Model(\"full_allocation\")\n",
    "\n",
    "n = len(relevant_warehouses)\n",
    "m = len(demand)\n",
    "\n",
    "# Create an array of driving times based on the df_distance DataFrame\n",
    "t = df_distance.drivingTime_hrs\n",
    "\n",
    "# Amount to take per Warehouse\n",
    "y = model.addVars(m, n, vtype=GRB.INTEGER, name=\"Single_Warehouse_Allocation\")\n",
    "\n",
    "# National Allocation\n",
    "X = model.addVars(n, vtype=GRB.INTEGER, name=\"National_Allocation\")\n",
    "\n",
    "# Total national endowment constraint\n",
    "model.addConstr(gp.quicksum(X[i] for i in range(n)) == 40811, name=\"Total_National_Endowment\")\n",
    "\n",
    "for k in range(m):\n",
    "    model.addConstr(y[k, i] <= X[i])\n",
    "\n",
    "# Demand and warehouse constraints for each scenario\n",
    "for k in range(m):\n",
    "    model.addConstr(gp.quicksum(y[k, i] for i in range(n)) == demand[k], name=f\"Meet_Demand_K:{k}\")\n",
    "    for i, supplies in enumerate(relevant_warehouses):\n",
    "        model.addConstr(y[k, i] <= supplies[2], name=f\"warehouse_endowment_K:{k}_I:{i}\")\n",
    "\n",
    "# Objective function to minimize the weighted driving time using T as a parameter\n",
    "objective = gp.quicksum(\n",
    "    probs[k] * gp.quicksum(t[i] * y[k, i] for i in range(n))\n",
    "    for k in range(m)\n",
    ")\n",
    "\n",
    "# Optimize model\n",
    "model.setObjective(objective, GRB.MINIMIZE)\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 A Few Final Tidbits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our overall framework, we can extend it fairly easily to better model real-life scenarios. Let's look at two final pieces of the puzzle that ESUPS considers in their model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost**\n",
    "\n",
    "Along with how long it takes to get items to a disaster relief site, it's also important to consider the cost to accomplish it. It might be a few hours faster to charter a jet to deliver blankets in the aftermath of a disaster, however, if it is 100x more expensive than by truck, that may constrain the organization from buying more blankets, chartering more trucks, or making it difficult to resupply for future disasters. So just as we solve for ways to minimize time, it can be important for firms with limited resources to make sure their money is being used to do the most good it can.\n",
    "\n",
    "So how do we do this? It's fairly simple. Our time matrix, which we've been using to show how close or far buildings are from the disaster relief site, is just a set of predefined weights/discounts. So, if we change the numbers to reflect the cost of transit, then suddenly we're solving a cost-minimization problem! In fact, the substitution is so one-to-one, that besides switching $\\tau_{ij}$ for $c_{ij}$, we don't have to change the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Travel Mode**\n",
    "\n",
    "The second additional facet considered in our real-life model that we haven't encountered yet is transportation mode. We alluded to it a little in the cost section, but often there is the option to fly or ship goods into a region, which can be especially useful when far away or the roads are clogged or otherwise unusable (such is often the case after a disaster).\n",
    "\n",
    "So how do we implement this? Well let's take a look back at $y_i^k$, our variable which says how many goods to send from warehouse $i$ to disaster $k$. All we want to do is reflect and update the description: how many goods to send from warehouse $i$ to disaster $k$ via mode $r$. This can easily be represented as $y_{ir}^k$, let's explain what's happened. Before this $y$ was an array of length $K$ with each index holding sub array of length $I$ (which we could also write as size $K \\times I$), now each index in our subarrays also have an array of length $3$ to represent how much is sent via truck, plane, or boat. So, our final array is of dimensions $K \\times I \\times R $. This may seem intimidating at first, but remember, adding a dimension just means adding one more nested for loop!\n",
    "\n",
    "Let's look at how we would implement this. Remember, from a math point of view, all we've done is say $y_i^k$ can be broken down into $3$ modes instead of 1. So, it's rewritten as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\min_{X,Y} \\sum_k P^k \\sum_i \\sum_r \\tau_{irj}\\cdot y^k_{ir}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{s.t.}  \\\\\n",
    "\\sum_{i}\\sum_{r} & y^k_{ir}&=d^k & & \\hspace{.2cm} \\text{(total supplies sent must meet demand)}\\\\\n",
    "\\sum_{r}  & y^k_{ir}       &\\leq x_i & \\forall i \\in I& \\hspace{.2cm}\\text{(you can't send more than a warehouse has)}\\\\\n",
    "\\sum_{i} & x_i&=\\chi & & \\hspace{.2cm} \\text{(we allocate all supplies and no more)}\\\\\n",
    "& y^k_{ir} &\\geq 0, \\space &\\forall r\\in R, i \\in I& \\hspace{.2cm} \\text{(you can't send negative supplies)}\\\\\n",
    "\\\\\n",
    "& x_{i} &\\geq 0 , \\space &\\forall i \\in I& \\hspace{.2cm} \\text{(you can't allocate negative supplies)}\\\\\n",
    "\n",
    "\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've added a few more sums here, but remember, in math, a sum is just a for loop. $\\sum_r$ is the equivalent to `for r in R:`. So how would we implement it in the format we've been using so far? This is going to be left as an open-ended exercise to the reader! If you get stuck, you can reference the production solver we'll be exploring below, which includes the mode of travel but is set up in a different approach than we've been using so far!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open-Ended Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Interpreting the Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's look at how much slower our real life allocations are in comparison to the optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhancing System Performance with the Balance Metric\n",
    "\n",
    "In humanitarian logistics, the efficiency of inventory allocation directly impacts the ability to respond swiftly and cost-effectively to disasters. The **Balance Metric** $(D)$ is a critical tool developed to evaluate the alignment of current inventory distribution with an optimal allocation. This metric is particularly valuable in contexts where multiple organizations independently manage inventory across various depots, without a centralized coordination mechanism.\n",
    "\n",
    "##### Definition and Calculation of the Balance Metric\n",
    "\n",
    "The balance metric $(D)$ is defined as the ratio between the actual objective value (either cost or time) of the current inventory allocation $V(X)$ and the optimal objective value $V(A')$ given the same overall capacity:\n",
    "\n",
    "$$ D = \\frac{V(A)}{V(A')}  $$\n",
    "\n",
    "Here:\n",
    "-  $V(A)$: Represents the current system-wide cost or time to meet demand based on the existing inventory allocation \\(X\\).\n",
    "-  $V(A')$: Represents the minimized cost or time if the inventory were optimally distributed across all depots.\n",
    "\n",
    "##### Interpretation of the Balance Metric\n",
    "\n",
    "1. **Optimal Inventory Allocation**:\n",
    "   The optimal value of $D$ is 1. This occurs when the current allocation perfectly aligns with the optimal allocation, meaning no further reallocation could reduce costs or response times.\n",
    "\n",
    "2. **Identifying Imbalances**:\n",
    "   When $D > 1$, the system is considered \"out-of-balance.\" A value of 1.2, for example, implies that the current allocation incurs 20% higher costs or longer response times compared to an optimal arrangement. This indicates a potential for improvement by reallocating resources more effectively.\n",
    "\n",
    "3. **Guiding System Improvements**:\n",
    "   The balance metric is not only an indicator of inefficiency but also a guide for decision-making. By identifying locations or items with the highest imbalance, decision-makers can prioritize inventory reallocations that would yield the most significant improvements in terms of cost savings or faster response times.\n",
    "\n",
    "##### Practical Applications in Humanitarian Logistics\n",
    "\n",
    "The balance metric offers several practical applications for optimizing humanitarian response efforts:\n",
    "\n",
    "- **Strategic Reallocation of Resources**:\n",
    "  Organizations can use the balance metric to identify under-stocked or over-stocked depots and adjust inventory levels accordingly. This strategic reallocation can significantly enhance response times or reduce costs, especially in multi-organizational contexts where coordination is limited.\n",
    "\n",
    "- **Sensitivity to Network Changes**:\n",
    "  The balance metric is responsive to changes in the logistics network. For example, if a new depot is added in a high-risk area and remains under-stocked, the balance metric will reflect this imbalance, prompting an assessment of whether inventory should be redistributed to better leverage the new depot.\n",
    "\n",
    "- **Decision-Making in Real-Time Operations**:\n",
    "  By continuously monitoring the balance metric as part of a real-time dashboard, operational managers can be alerted to changes that may impact overall system performance. This enables them to make data-driven decisions quickly, improving the overall resilience and responsiveness of the humanitarian supply chain.\n",
    "\n",
    "##### Limitations and Considerations\n",
    "\n",
    "While the balance metric provides valuable insights into inventory allocation efficiency, it is important to consider its limitations:\n",
    "\n",
    "- **Impact of Extreme Events**:\n",
    "  The balance metric can be influenced by extreme scenarios, such as very large-scale disasters that significantly impact the calculated demand. As a result, it should be interpreted alongside other metrics, such as the fraction of demand served ($g$) or the weighted fraction of disasters completely served ($d$), to provide a more comprehensive picture of system performance.\n",
    "\n",
    "- **Dependence on Data Quality and Model Assumptions**:\n",
    "  The accuracy of the balance metric depends on the quality of input data and the assumptions made in the model. Ensuring robust and accurate data collection processes and regularly updating model parameters to reflect real-world conditions are essential for maintaining the reliability of the metric.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "The balance metric $D$ offers a powerful tool for evaluating and improving the efficiency of inventory allocation in humanitarian logistics. By identifying imbalances and guiding strategic reallocation decisions, this metric can help organizations optimize their response efforts, ensuring that resources are used most effectively to meet the needs of affected populations during disasters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='End'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurobi_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
